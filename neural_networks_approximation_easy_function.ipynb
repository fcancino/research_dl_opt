{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created a scatter plot of the output of the neural network for the simple function. Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0xa8390f2c>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.colors' has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.colors' has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def f1(x,y):\n",
    "\t\"\"\"\n",
    "\tThe function you told me\n",
    "\t\"\"\"\n",
    "\treturn x**2 + y**2 - 2/ np.pi\n",
    "\n",
    "\n",
    "\n",
    "##Generating the training data\n",
    "train_data = np.random.uniform(0,1,(10000, 2))\n",
    "train_target = []\n",
    "\n",
    "\n",
    "for i in train_data:\n",
    "\tz = f1(i[0],i[1])\n",
    "\tif z > 0:\n",
    "\t\ttrain_target.append(0)\n",
    "\telse:\n",
    "\t\ttrain_target.append(1)\n",
    "\n",
    "train_target = np.transpose(train_target)\n",
    "\n",
    "##Generating the testing data\n",
    "test_data = np.random.uniform(-1,1,(1000, 2))\n",
    "test_target = []\n",
    "\n",
    "##In this for loop I am filling the test target data\n",
    "for i in test_data:\n",
    "\tz = f1(i[0],i[1])\n",
    "\tif z > 0:\n",
    "\t\ttest_target.append(0)\n",
    "\telse:\n",
    "\t\ttest_target.append(1)\n",
    "\n",
    "##Neural Network\n",
    "clf = MLPClassifier(alpha=1e-4, early_stopping=False, max_iter=70000, activation='relu',\n",
    "                    momentum=0.5,solver='adam',hidden_layer_sizes=(4, 4, 4), random_state=1)\n",
    "\n",
    "\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "# print('current loss computed with the loss function: ',clf.loss_)\n",
    "# print('coefs : ', clf.coefs_)\n",
    "# print('intercepts: ',clf.intercepts_)\n",
    "# print(' number of iterations the solver: ', clf.n_iter_)\n",
    "# print('num of layers: ', clf.n_layers_)\n",
    "# print('Num of o/p: ', clf.n_outputs_)\n",
    "\n",
    "print( 'accuracy: ',clf.score( test_data, test_target ))\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "Z = clf.predict(test_data)\n",
    "\n",
    "ax.scatter3D(test_data[:,0], test_data[:,1], Z, c=Z, cmap='Greens')\n",
    "\n",
    "\n",
    "#plt.show() Plot doesn't work here. I will add images. \n",
    "#There are some errors in this interpreter. There are no errors in my laptop. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the graph of the neural network function for 2 hidden layers of 4 nodes each one with accuracy 0.616:\n",
    "\n",
    "<img src=\"2layers_4nodes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the graph of the neural network function for 2 hidden layers of 4 nodes each one with accuracy 0.628:\n",
    "\n",
    "<img src=\"3layers_4nodes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the graph of the neural network function for 3 hidden layers of 4 nodes each one with accuracy 0.6:\n",
    "\n",
    "<img src=\"4layers_4nodes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at what happens when we have 5 layers. The accuracy goes up to 0.742. \n",
    "<img src=\"5layers_4nodes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually it seems it was just luck. I run it several more times and it behaves similar to the previous ones graphe. I tried graphing neural networks with different layers and all of them seem to work the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
